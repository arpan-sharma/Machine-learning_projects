{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ar_Handwritten Digit Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpE2LdxJ08KStCvuuTWCNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arpan-sharma/Machine-learning_projects/blob/main/Ar_Handwritten_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QxdFb4OcvTY",
        "outputId": "77095e87-c874-42a1-b102-2f5191695d4f"
      },
      "source": [
        "print(\"üôè ‡•ê üôè\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üôè ‡•ê üôè\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7-HyqHWkoEA"
      },
      "source": [
        "# 1. Import the libraries and load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoc7gMtwf7Ak"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras import utils as np_utils\n",
        "# from keras import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF0E3bvehOMS"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtOmJ2EulFV-",
        "outputId": "459649a8-b538-4c76-a466-cee53def795a"
      },
      "source": [
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rvWApn2lebV"
      },
      "source": [
        "# 2. Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmC5PRwslMZD"
      },
      "source": [
        "#The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network.\n",
        "# The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1).\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd2TdBX3lop1",
        "outputId": "d8c114ff-23dd-476d-cf56-1f41a8c20e26"
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgiDGjYzpi1M"
      },
      "source": [
        "# 3. Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YgTDap_mIuG"
      },
      "source": [
        "# Now we will create our CNN model in Python data science project. A CNN model generally consists of convolutional and pooling layers.\n",
        "# It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems.\n",
        "# The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model.\n",
        "# We will then compile the model with the Adadelta optimizer.\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gsQ5DTsqBbt"
      },
      "source": [
        "# 4. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFc3302Ep7pq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb56493-b735-4cf0-ad89-d4cfd4ad4c0c"
      },
      "source": [
        "# The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n",
        "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
        "print(\"The model has successfully trained\")\n",
        "\n",
        "model.save('mnist.h5')\n",
        "print(\"Saving the model as mnist.h5\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 188s 365ms/step - loss: 2.2903 - accuracy: 0.1356 - val_loss: 2.2582 - val_accuracy: 0.3288\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 171s 364ms/step - loss: 2.2530 - accuracy: 0.2407 - val_loss: 2.2092 - val_accuracy: 0.4716\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 169s 359ms/step - loss: 2.2037 - accuracy: 0.3436 - val_loss: 2.1413 - val_accuracy: 0.6026\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 169s 361ms/step - loss: 2.1370 - accuracy: 0.4340 - val_loss: 2.0441 - val_accuracy: 0.6914\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 170s 362ms/step - loss: 2.0371 - accuracy: 0.5252 - val_loss: 1.9005 - val_accuracy: 0.7483\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 171s 364ms/step - loss: 1.8928 - accuracy: 0.5998 - val_loss: 1.6975 - val_accuracy: 0.7798\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 171s 364ms/step - loss: 1.6981 - accuracy: 0.6464 - val_loss: 1.4450 - val_accuracy: 0.7992\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 1.4747 - accuracy: 0.6728 - val_loss: 1.1884 - val_accuracy: 0.8112\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 173s 368ms/step - loss: 1.2607 - accuracy: 0.6943 - val_loss: 0.9761 - val_accuracy: 0.8230\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 172s 366ms/step - loss: 1.0828 - accuracy: 0.7168 - val_loss: 0.8224 - val_accuracy: 0.8333\n",
            "The model has successfully trained\n",
            "Saving the model as mnist.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0vntddIfBV_"
      },
      "source": [
        "# 5. Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgP1WB83qbXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703a3cef-9373-4da7-dc0d-340f8435d02d"
      },
      "source": [
        "#We have 10,000 images in our dataset which will be used to evaluate how good our model works. The testing data was not involved in the training of the data therefore,\n",
        "#it is new data for our model. The MNIST dataset is well balanced so we can get around 99% accuracy.\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.8224136829376221\n",
            "Test accuracy: 0.833299994468689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnTMS3PCgseF"
      },
      "source": [
        "# 6. Create GUI to predict digits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aTmv3VfnhbzE",
        "outputId": "5400b190-71a3-4b16-b9cd-ae2b91499c9e"
      },
      "source": [
        "# pip install win32gui\n",
        "import platform\n",
        "platform.system()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Linux'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubMehAIfgeJH"
      },
      "source": [
        "from tkinter import *\n",
        "import tkinter as tk\n",
        "from PIL import ImageGrab, Image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4jvbDjhOMy"
      },
      "source": [
        "def predict_digit(img):\n",
        "    #resize image to 28x28 pixels\n",
        "    img = img.resize((28,28))\n",
        "    #convert rgb to grayscale\n",
        "    img = img.convert('L')\n",
        "    img = np.array(img)\n",
        "    #reshaping to support our model input and normalizing\n",
        "    img = img.reshape(1,28,28,1)\n",
        "    img = img/255.0\n",
        "    #predicting the class\n",
        "    res = model.predict([img])[0]\n",
        "    return np.argmax(res), max(res)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyfJ5sbVlNvw"
      },
      "source": [
        "!apt-get install python3-tk\n",
        "### CREATE VIRTUAL DISPLAY ###\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4p842UtltCE",
        "outputId": "da8f782d-9c16-4659-fae2-4af888e65bcc"
      },
      "source": [
        "%matplotlib inline\n",
        "!apt install ghostscript python3-tk\n",
        "chunked_sentence = '(S (NP this tree) (VP (V is) (AdjP pretty)))'\n",
        "from nltk.tree import Tree\n",
        "\n",
        "from IPython.display import display"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ghostscript is already the newest version (9.26~dfsg+0-0ubuntu0.18.04.14).\n",
            "python3-tk is already the newest version (3.6.9-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_CMnf4tkmV7"
      },
      "source": [
        "# class App(tk.Tk):\n",
        "#     def __init__(self):\n",
        "#         tk.Tk.__init__(self)\n",
        "\n",
        "#         self.x = self.y = 0\n",
        "\n",
        "#         # Creating elements\n",
        "#         self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
        "#         self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
        "#         self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
        "#         self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
        "\n",
        "#         # Grid structure\n",
        "#         self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
        "#         self.label.grid(row=0, column=1,pady=2, padx=2)\n",
        "#         self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
        "#         self.button_clear.grid(row=1, column=0, pady=2)\n",
        "\n",
        "#         #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
        "#         self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
        "\n",
        "#     def clear_all(self):\n",
        "#         self.canvas.delete(\"all\")\n",
        "\n",
        "#     def classify_handwriting(self):\n",
        "#         HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
        "#         rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
        "#         im = ImageGrab.grab(rect)\n",
        "\n",
        "#         digit, acc = predict_digit(im)\n",
        "#         self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
        "\n",
        "#     def draw_lines(self, event):\n",
        "#         self.x = event.x\n",
        "#         self.y = event.y\n",
        "#         r=8\n",
        "#         self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
        "\n",
        "# app = App()\n",
        "# mainloop()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAKRTOXC6A9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}